from flask import Flask, jsonify, request
from flask_cors import CORS
import pandas as pd
import numpy as np
from geopy.distance import geodesic
from sklearn.cluster import DBSCAN
import os
import matplotlib.pyplot as plt
import requests
import time
import geopandas as gpd
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
KAKAO_API_KEY = os.getenv("KAKAO_API_KEY")
BACKEND_ORIGIN = os.getenv("BACKEND_ORIGIN")

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": BACKEND_ORIGIN}})


# ğŸ“Œ ì£¼ì†Œ â†’ ì¢Œí‘œ ë³€í™˜ í•¨ìˆ˜
def kakao_geocode(address):
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": address}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=5)
        result = response.json()
        if result["documents"]:
            first = result["documents"][0]
            return float(first["y"]), float(first["x"])  # ìœ„ë„, ê²½ë„
        else:
            return None, None
    except Exception as e:
        print(f"âŒ ì£¼ì†Œ ë³€í™˜ ì‹¤íŒ¨: {address} / {e}")
        return None, None


# âœ… ì†Œë°©ì„œ ë° ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ ì¢Œí‘œë§Œ ë°˜í™˜í•˜ëŠ” API
@app.route('/get-coordinates', methods=['GET'])
def get_coordinates():
    try:
        print("ğŸ“Œ ì†Œë°©ì„œ ë° ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ ì¢Œí‘œ ìš”ì²­ ìˆ˜ì‹ ")

        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        base_path = os.path.dirname(__file__)
        fire_station_file = os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì†Œë°©ì„œ_ì¢Œí‘œ_ì¹´ì¹´ì˜¤.csv")
        child_safety_file = os.path.join(base_path, "data/ë°ì´í„°ì´ˆì•ˆ/ì „êµ­ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­í‘œì¤€ë°ì´í„°.csv")

        # ì†Œë°©ì„œ ì¢Œí‘œ ë¡œë“œ
        fire_stations = []
        if os.path.exists(fire_station_file):
            try:
                df_fire = pd.read_csv(fire_station_file)
                # ì¢Œí‘œë§Œ ì¶”ì¶œ (ì£¼ì†Œ ì •ë³´ ì œì™¸)
                for _, row in df_fire.iterrows():
                    if not pd.isna(row['ìœ„ë„']) and not pd.isna(row['ê²½ë„']):
                        fire_stations.append([float(row['ìœ„ë„']), float(row['ê²½ë„'])])
                print(f"âœ… ì†Œë°©ì„œ ì¢Œí‘œ {len(fire_stations)}ê°œ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì†Œë°©ì„œ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")

        # ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ ì¢Œí‘œ ë¡œë“œ
        safety_zones = []
        if os.path.exists(child_safety_file):
            try:
                # ì¸ì½”ë”© ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
                encodings = ['utf-8', 'euc-kr', 'cp949']
                df_safety = None

                for encoding in encodings:
                    try:
                        df_safety = pd.read_csv(child_safety_file, encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue

                if df_safety is not None:
                    # ìœ„ë„, ê²½ë„ ì»¬ëŸ¼ ì°¾ê¸°
                    lat_col = None
                    lng_col = None
                    for col in df_safety.columns:
                        if 'ìœ„ë„' in col:
                            lat_col = col
                        elif 'ê²½ë„' in col:
                            lng_col = col

                    # ì¢Œí‘œë§Œ ì¶”ì¶œ (ì£¼ì†Œ ì •ë³´ ì œì™¸)
                    for _, row in df_safety.iterrows():
                        if lat_col and lng_col and not pd.isna(row[lat_col]) and not pd.isna(row[lng_col]):
                            safety_zones.append([float(row[lat_col]), float(row[lng_col])])
                    print(f"âœ… ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ ì¢Œí‘œ {len(safety_zones)}ê°œ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")

        return jsonify({
            'fireStations': fire_stations,
            'safetyZones': safety_zones
        })

    except Exception as e:
        print(f"âŒ ì¢Œí‘œ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500


# âœ… 1. ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰API
@app.route('/recommend', methods=['POST'])
def recommend():
    try:
        print("ğŸ“Œ [1] ì¶”ì²œ ìš”ì²­ ìˆ˜ì‹ ë¨")

        # === íŒŒì¼ ê²½ë¡œ ì„¤ì • ===
        base_path = os.path.dirname(__file__)
        population_density_file = os.path.join(base_path, "data/ë°ì´í„°ì´ˆì•ˆ/ì¸êµ¬ë°€ë„ ë°ì´í„°.txt")
        child_safety_zone_file = os.path.join(base_path, "data/ë°ì´í„°ì´ˆì•ˆ/ì „êµ­ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­í‘œì¤€ë°ì´í„°.csv")
        geo_mapping_file = os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì§€ì—­ì½”ë“œ_ì¢Œí‘œ.csv")
        fire_station_file = os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì†Œë°©ì„œ_ì¢Œí‘œ_ì¹´ì¹´ì˜¤.csv")
        result_output_file = os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì¶”ì²œ_ìˆ˜ê±°í•¨_ìœ„ì¹˜.csv")

        print("ğŸ“Œ [2] ì¸êµ¬ ë°€ë„ ë°ì´í„° ë¡œë”© ì¤‘...")
        df_population = pd.read_csv(population_density_file, delimiter='^', header=None,
                                    names=['ì—°ë„', 'ì§€ì—­ì½”ë“œ', 'ì§€í‘œì½”ë“œ', 'ì¸êµ¬ë°€ë„'])
        df_population = df_population[df_population['ì§€í‘œì½”ë“œ'] == 'to_in_003']
        # ëª¨ë“  ì§€ì—­ í¬í•¨
        df_population_filtered = df_population.copy()

        print("ğŸ“Œ [3] ìœ„ê²½ë„ ë§¤í•‘ ì¤‘...")
        df_geo = pd.read_csv(geo_mapping_file).dropna(subset=['ìœ„ë„', 'ê²½ë„'])
        df_population_filtered = df_population_filtered.merge(df_geo, on="ì§€ì—­ì½”ë“œ", how="left")

        print("ğŸ“Œ [4] ê³ ë°€ë„ ì§€ì—­ í•„í„°ë§ ì¤‘...")
        df_population_filtered['ì¸êµ¬ë°€ë„í‰ê· '] = df_population_filtered['ì¸êµ¬ë°€ë„'].rolling(window=5, center=True, min_periods=1).mean()
        df_population_filtered['ë°€ë„ì°¨ì´'] = df_population_filtered['ì¸êµ¬ë°€ë„'] - df_population_filtered['ì¸êµ¬ë°€ë„í‰ê· ']
        density_threshold = 0.8
        high_density_areas = df_population_filtered[
            df_population_filtered['ë°€ë„ì°¨ì´'] > df_population_filtered['ë°€ë„ì°¨ì´'].quantile(density_threshold)].copy()

        min_recommendations = 20
        while len(high_density_areas) < min_recommendations and density_threshold > 0.5:
            density_threshold -= 0.05
            high_density_areas = df_population_filtered[
                df_population_filtered['ë°€ë„ì°¨ì´'] > df_population_filtered['ë°€ë„ì°¨ì´'].quantile(density_threshold)].copy()

        print(f"âœ… ê³ ë°€ë„ ì§€ì—­ í›„ë³´ ê°œìˆ˜: {len(high_density_areas)}")

        print("ğŸ“Œ [5] ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­ í•„í„°ë§ ì¤‘...")
        df_child_safety = pd.read_csv(child_safety_zone_file, encoding='cp949')[['ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ', 'ê²½ë„', 'ìœ„ë„']].dropna()
        safety_distance = 0.3
        safe_high_density_areas = []

        for _, pop_row in high_density_areas.iterrows():
            pop_loc = (pop_row['ìœ„ë„'], pop_row['ê²½ë„'])
            if any(geodesic(pop_loc, (row['ìœ„ë„'], row['ê²½ë„'])).km < safety_distance for _, row in
                   df_child_safety.iterrows()):
                continue
            safe_high_density_areas.append(pop_row)

        df_safe = pd.DataFrame(safe_high_density_areas)
        print(f"âœ… ì–´ë¦°ì´ ë³´í˜¸êµ¬ì—­ ì œì™¸ í›„ ì§€ì—­ ìˆ˜: {len(df_safe)}")

        print("ğŸ“Œ [6] ì†Œë°©ì„œ ê±°ë¦¬ í•„í„°ë§ ì¤‘...")
        df_fire = pd.read_csv(fire_station_file).dropna(subset=['ìœ„ë„', 'ê²½ë„'])
        fire_coords = df_fire[['ìœ„ë„', 'ê²½ë„']].values
        distances_to_fire = []
        for coord in df_safe[['ìœ„ë„', 'ê²½ë„']].values:
            fire_distances = [geodesic(coord, fire_coord).km for fire_coord in fire_coords]
            distances_to_fire.append(min(fire_distances))
        distances_to_fire = np.array(distances_to_fire)

        distance_threshold = np.percentile(distances_to_fire, 90)
        df_safe['is_far'] = distances_to_fire > distance_threshold
        df_safe = df_safe[df_safe['is_far'] == False]
        print(f"âœ… ì†Œë°©ì„œ ê±°ë¦¬ ì œì™¸ í›„ ì§€ì—­ ìˆ˜: {len(df_safe)}")

        print("ğŸ“Œ [7] DBSCAN êµ°ì§‘í™” ìˆ˜í–‰ ì¤‘...")
        df_final_filtered = df_safe.copy()
        coords = np.radians(df_final_filtered[['ìœ„ë„', 'ê²½ë„']].values)
        epsilon_radians = (400 / 1000) / 6371
        dbscan = DBSCAN(eps=epsilon_radians, min_samples=2, metric='haversine')
        df_final_filtered['cluster'] = dbscan.fit_predict(coords)

        # êµ°ì§‘í™”ë˜ì§€ ì•Šì€ ì¢Œí‘œ (ë…¸ì´ì¦ˆ)
        df_noise = df_final_filtered[df_final_filtered['cluster'] == -1].copy()
        df_noise['point_type'] = 'noise'  # êµ°ì§‘í™”ë˜ì§€ ì•Šì€ í¬ì¸íŠ¸ í‘œì‹œ

        # êµ°ì§‘í™”ëœ ì¢Œí‘œë“¤
        df_clustered = df_final_filtered[df_final_filtered['cluster'] != -1].copy()
        df_clustered['point_type'] = 'cluster_member'  # êµ°ì§‘ì— í¬í•¨ëœ í¬ì¸íŠ¸ í‘œì‹œ

        # êµ°ì§‘ ì¤‘ì‹¬ì  ê³„ì‚°
        cluster_centroids = df_clustered.groupby('cluster').agg({'ìœ„ë„': 'mean', 'ê²½ë„': 'mean'}).reset_index()
        cluster_centroids['point_type'] = 'centroid'  # êµ°ì§‘ ì¤‘ì‹¬ì  í‘œì‹œ

        # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°
        final_recommendations = pd.concat([
            cluster_centroids[['ìœ„ë„', 'ê²½ë„', 'cluster', 'point_type']],
            df_clustered[['ìœ„ë„', 'ê²½ë„', 'cluster', 'point_type']],
            df_noise[['ìœ„ë„', 'ê²½ë„', 'cluster', 'point_type']]
        ])

        print(f"âœ… êµ°ì§‘í™” ì™„ë£Œ - êµ°ì§‘ ìˆ˜: {df_clustered['cluster'].nunique()}, ë…¸ì´ì¦ˆ ìˆ˜: {len(df_noise)}")

        print("ğŸ“Œ [8] ê²°ê³¼ CSV ì €ì¥ ì¤‘...")
        final_recommendations.to_csv(result_output_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ¯ ì¶”ì²œ ì™„ë£Œ! ìœ„ì¹˜ ìˆ˜: {len(final_recommendations)}")
        print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {result_output_file}")

        print("ğŸ“Œ [9] ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
        plt.figure(figsize=(10, 6))
        # êµ°ì§‘í™”ë˜ì§€ ì•Šì€ ì¢Œí‘œ (ë…¸ì´ì¦ˆ)
        noise_points = final_recommendations[final_recommendations['point_type'] == 'noise']
        plt.scatter(noise_points['ê²½ë„'], noise_points['ìœ„ë„'], c='green', label='Non-clustered (Noise)', s=50)

        # êµ°ì§‘ì— í¬í•¨ëœ ì¢Œí‘œë“¤
        cluster_members = final_recommendations[final_recommendations['point_type'] == 'cluster_member']
        plt.scatter(cluster_members['ê²½ë„'], cluster_members['ìœ„ë„'], c='blue', label='Cluster Members', s=50)

        # êµ°ì§‘ ì¤‘ì‹¬ì 
        centroids = final_recommendations[final_recommendations['point_type'] == 'centroid']
        plt.scatter(centroids['ê²½ë„'], centroids['ìœ„ë„'], c='red', label='Cluster Centroids', s=100, marker='x')

        plt.legend()
        plt.title("Recommended Locations")
        plt.xlabel("Longitude")
        plt.ylabel("Latitude")
        plt.tight_layout()
        plt.savefig(os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì¶”ì²œ_ìˆ˜ê±°í•¨_ì‹œê°í™”.png"))
        print("ğŸ–¼ï¸ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ")

        return jsonify({"message": "ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ì™„ë£Œ, ê²°ê³¼ ì €ì¥ë¨ âœ…"}), 200

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/recommend/compare', methods=['POST'])
def compare_existing_with_recommended():
    try:
        print("ğŸ“Œ [compare] ê¸°ì¡´ ìˆ˜ê±°í•¨ê³¼ ì¶”ì²œ ìœ„ì¹˜ ë¹„êµ ì‹œì‘")

        # === ìš”ì²­ ë³¸ë¬¸ì—ì„œ ê¸°ì¡´ ìˆ˜ê±°í•¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ===
        if not request.is_json:
            print("âŒ ìš”ì²­ ë³¸ë¬¸ì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return jsonify({"error": "ìš”ì²­ ë³¸ë¬¸ì´ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."}), 400

        existing_boxes_raw = request.json
        print(f"ğŸ“¦ ê¸°ì¡´ ìˆ˜ê±°í•¨ ì‘ë‹µ ìˆ˜: {len(existing_boxes_raw)}")

        # ì¤‘ìš”: ì‘ë‹µ êµ¬ì¡° í™•ì¸ ë° ì²˜ë¦¬
        # ì‘ë‹µì´ {'box': {...}} í˜•íƒœë¡œ ì¤‘ì²©ë˜ì–´ ìˆìœ¼ë¯€ë¡œ 'box' í‚¤ ë‚´ë¶€ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ
        existing_boxes = []
        for item in existing_boxes_raw:
            if isinstance(item, dict) and 'box' in item:
                existing_boxes.append(item['box'])
            else:
                existing_boxes.append(item)  # ì¤‘ì²©ë˜ì§€ ì•Šì€ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©

        print(f"ğŸ“¦ ì²˜ë¦¬ëœ ê¸°ì¡´ ìˆ˜ê±°í•¨ ìˆ˜: {len(existing_boxes)}")

        # ì²« 5ê°œ ë°•ìŠ¤ ë°ì´í„° ë¡œê¹… (ë˜ëŠ” ì „ì²´ê°€ 5ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´)
        sample_size = min(5, len(existing_boxes))
        print(f"ğŸ“‹ ê¸°ì¡´ ìˆ˜ê±°í•¨ ìƒ˜í”Œ ë°ì´í„° ({sample_size}ê°œ):")
        for i in range(sample_size):
            print(f"  - Box {i + 1}: {existing_boxes[i]}")

        # === ê¸°ì¡´ ìˆ˜ê±°í•¨ì˜ ì¢Œí‘œ íŒŒì‹± ===
        existing_coords = []
        valid_coords_count = 0
        invalid_coords_count = 0

        print("ğŸ§® ê¸°ì¡´ ìˆ˜ê±°í•¨ ì¢Œí‘œ íŒŒì‹± ì‹œì‘...")
        for idx, box in enumerate(existing_boxes):
            location_str = box.get("location")
            box_id = box.get("id", "ì•Œ ìˆ˜ ì—†ìŒ")
            box_name = box.get("name", "ì´ë¦„ ì—†ìŒ")

            if not location_str:
                print(f"âš ï¸ ìœ„ì¹˜ ì •ë³´ ì—†ìŒ: Box ID {box_id}, Name: {box_name}")
                invalid_coords_count += 1
                continue

            if "POINT" not in location_str:
                print(f"âš ï¸ POINT í˜•ì‹ì´ ì•„ë‹˜: Box ID {box_id}, Name: {box_name}, Location: {location_str}")
                invalid_coords_count += 1
                continue

            try:
                # ì¢Œí‘œ íŒŒì‹± ì‹œë„
                coords_part = location_str.replace("POINT (", "").replace(")", "").strip()
                lng, lat = map(float, coords_part.split())
                existing_coords.append((lat, lng))  # ìœ„ë„, ê²½ë„
                valid_coords_count += 1

                # ì²˜ìŒ 10ê°œì™€ ë§ˆì§€ë§‰ 10ê°œ ì¢Œí‘œë§Œ ì¶œë ¥ (ë˜ëŠ” ì „ì²´ê°€ 20ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´)
                if idx < 10 or idx >= len(existing_boxes) - 10:
                    print(f"  âœ“ Box {idx + 1} (ID: {box_id}): ìœ„ë„={lat}, ê²½ë„={lng}, ì›ë³¸={location_str}")
            except ValueError as e:
                print(f"âš ï¸ ìœ„ì¹˜ íŒŒì‹± ì‹¤íŒ¨: Box ID {box_id}, Name: {box_name}, Location: {location_str}, ì˜¤ë¥˜: {e}")
                invalid_coords_count += 1

        print(f"ğŸ“Š ì¢Œí‘œ íŒŒì‹± ê²°ê³¼: ì„±ê³µ={valid_coords_count}, ì‹¤íŒ¨={invalid_coords_count}, ì´={len(existing_boxes)}")
        print(f"ğŸ—ºï¸ ìœ íš¨í•œ ê¸°ì¡´ ìˆ˜ê±°í•¨ ì¢Œí‘œ ìˆ˜: {len(existing_coords)}")

        # === ì¶”ì²œ ìœ„ì¹˜ CSV ë¶ˆëŸ¬ì˜¤ê¸° ===
        base_path = os.path.dirname(__file__)
        recommended_file = os.path.join(base_path, "data/ì‚°ì¶œë°ì´í„°/ì¶”ì²œ_ìˆ˜ê±°í•¨_ìœ„ì¹˜.csv")
        print(f"ğŸ“‚ ì¶”ì²œ ìœ„ì¹˜ CSV íŒŒì¼ ê²½ë¡œ: {recommended_file}")

        if not os.path.exists(recommended_file):
            print(f"âŒ ì¶”ì²œ ìœ„ì¹˜ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {recommended_file}")
            return jsonify({"error": "ì¶”ì²œ ìœ„ì¹˜ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        df_recommended = pd.read_csv(recommended_file)
        print(f"ğŸ“ ì¶”ì²œ ìœ„ì¹˜ ìˆ˜ (CSV): {len(df_recommended)}")
        print(f"ğŸ“‹ ì¶”ì²œ ìœ„ì¹˜ CSV ì»¬ëŸ¼: {df_recommended.columns.tolist()}")

        # êµ°ì§‘ ì¤‘ì‹¬ì ê³¼ ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ í•„í„°ë§ (ì‹¤ì œ ì¶”ì²œ ìœ„ì¹˜ë¡œ ì‚¬ìš©)
        df_centroids_noise = df_recommended[
            (df_recommended['point_type'] == 'centroid') |
            (df_recommended['point_type'] == 'noise')
            ]
        print(f"ğŸ“ ì¤‘ì‹¬ì  ë° ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ ìˆ˜: {len(df_centroids_noise)}")
        print(f"  - ì¤‘ì‹¬ì (centroid) ìˆ˜: {len(df_recommended[df_recommended['point_type'] == 'centroid'])}")
        print(f"  - ë…¸ì´ì¦ˆ(noise) ìˆ˜: {len(df_recommended[df_recommended['point_type'] == 'noise'])}")

        # === ë¹„êµ: ê¸°ì¡´ ìˆ˜ê±°í•¨ê³¼ 400m ì´ë‚´ì¸ ì¶”ì²œ ìœ„ì¹˜ ì œê±° ===
        filtered_centroids_noise = []
        valid_clusters = set()  # ìœ íš¨í•œ êµ°ì§‘ IDë¥¼ ì €ì¥í•  ì§‘í•©
        removed_count = 0  # ì‚­ì œëœ ìœ„ì¹˜ ê°œìˆ˜ ì¹´ìš´íŠ¸
        removed_details = []  # ì‚­ì œëœ ìœ„ì¹˜ì˜ ìƒì„¸ ì •ë³´

        print("ğŸ” ê¸°ì¡´ ìˆ˜ê±°í•¨ê³¼ ì¶”ì²œ ìœ„ì¹˜ ë¹„êµ ì‹œì‘...")
        for idx, row in df_centroids_noise.iterrows():
            rec_point = (row["ìœ„ë„"], row["ê²½ë„"])
            too_close = False
            closest_distance = float('inf')
            closest_existing_point = None

            for exist_point in existing_coords:
                distance = geodesic(rec_point, exist_point).km
                if distance < closest_distance:
                    closest_distance = distance
                    closest_existing_point = exist_point

                if distance < 0.4:  # 400m ì´ë‚´
                    too_close = True
                    removed_count += 1  # ì‚­ì œëœ ìœ„ì¹˜ ì¹´ìš´íŠ¸ ì¦ê°€
                    removed_details.append({
                        "ì¶”ì²œ_ìœ„ë„": rec_point[0],
                        "ì¶”ì²œ_ê²½ë„": rec_point[1],
                        "ê¸°ì¡´_ìœ„ë„": exist_point[0],
                        "ê¸°ì¡´_ê²½ë„": exist_point[1],
                        "ê±°ë¦¬_km": distance,
                        "point_type": row["point_type"],
                        "cluster": int(row["cluster"])
                    })
                    break

            if not too_close:
                cluster_id = int(row["cluster"])
                filtered_centroids_noise.append({
                    "lat": rec_point[0],
                    "lng": rec_point[1],
                    "point_type": row["point_type"],
                    "cluster": cluster_id
                })

                # ìœ íš¨í•œ êµ°ì§‘ ID ì €ì¥ (ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ëŠ” -1ì´ë¯€ë¡œ ì œì™¸)
                if cluster_id != -1:
                    valid_clusters.add(cluster_id)

            # ì²˜ë¦¬ ì§„í–‰ ìƒí™© ë¡œê¹… (10% ë‹¨ìœ„)
            if idx % max(1, len(df_centroids_noise) // 10) == 0:
                print(f"  - ì²˜ë¦¬ ì¤‘: {idx}/{len(df_centroids_noise)} ({idx / len(df_centroids_noise) * 100:.1f}%)")

        # ì‚­ì œëœ ìœ„ì¹˜ ìƒì„¸ ì •ë³´ ë¡œê¹… (ìµœëŒ€ 10ê°œ)
        print(f"ğŸ—‘ï¸ ì‚­ì œëœ ì¶”ì²œ ìœ„ì¹˜ ìƒì„¸ ì •ë³´ (ìµœëŒ€ 10ê°œ):")
        for i, detail in enumerate(removed_details[:10]):
            print(f"  - ì‚­ì œ {i + 1}: ì¶”ì²œ({detail['ì¶”ì²œ_ìœ„ë„']}, {detail['ì¶”ì²œ_ê²½ë„']}) â†” " +
                  f"ê¸°ì¡´({detail['ê¸°ì¡´_ìœ„ë„']}, {detail['ê¸°ì¡´_ê²½ë„']}), " +
                  f"ê±°ë¦¬={detail['ê±°ë¦¬_km']:.3f}km, íƒ€ì…={detail['point_type']}, êµ°ì§‘={detail['cluster']}")

        # êµ°ì§‘ ë©¤ë²„ ì¶”ê°€ (ìœ íš¨í•œ êµ°ì§‘ì— ì†í•œ ë©¤ë²„ë§Œ)
        cluster_members = []
        df_members = df_recommended[df_recommended['point_type'] == 'cluster_member']
        print(f"ğŸ‘¥ êµ°ì§‘ ë©¤ë²„ ìˆ˜ (ì „ì²´): {len(df_members)}")

        for _, row in df_members.iterrows():
            cluster_id = int(row["cluster"])
            if cluster_id in valid_clusters:  # ìœ íš¨í•œ êµ°ì§‘ì— ì†í•œ ë©¤ë²„ë§Œ ì¶”ê°€
                cluster_members.append({
                    "lat": row["ìœ„ë„"],
                    "lng": row["ê²½ë„"],
                    "point_type": "cluster_member",
                    "cluster": cluster_id
                })

        # ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸°
        all_recommendations = filtered_centroids_noise + cluster_members

        print(f"âœ… í•„í„°ë§ í›„ ì¶”ì²œ ìœ„ì¹˜ ìˆ˜: {len(filtered_centroids_noise)} (ì¤‘ì‹¬ì  ë° ë…¸ì´ì¦ˆ)")
        print(f"  - ì¤‘ì‹¬ì (centroid): {len([p for p in filtered_centroids_noise if p['point_type'] == 'centroid'])}")
        print(f"  - ë…¸ì´ì¦ˆ(noise): {len([p for p in filtered_centroids_noise if p['point_type'] == 'noise'])}")
        print(f"âœ… ì‚­ì œëœ ì¶”ì²œ ìœ„ì¹˜ ìˆ˜: {removed_count}")  # ì‚­ì œëœ ìœ„ì¹˜ ìˆ˜ ì¶œë ¥
        print(f"âœ… í¬í•¨ëœ êµ°ì§‘ ë©¤ë²„ ìˆ˜: {len(cluster_members)}")
        print(f"âœ… ì´ ë°˜í™˜ ì¢Œí‘œ ìˆ˜: {len(all_recommendations)}")

        # ì‚­ì œëœ ìœ„ì¹˜ ìˆ˜ë¥¼ ì‘ë‹µ í—¤ë”ì— í¬í•¨
        response = jsonify(all_recommendations)
        response.headers['X-Removed-Locations'] = str(removed_count)
        return response, 200

    except Exception as e:
        import traceback
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return jsonify({"error": str(e)}), 500


@app.route('/upload-multiple', methods=['POST'])
def upload_multiple_files():
    try:
        files = request.files
        print(f"ğŸ“¥ ìˆ˜ì‹ ëœ íŒŒì¼ ëª©ë¡: {list(files.keys())}")

        save_dir = "data/ë°ì´í„°ì´ˆì•ˆ"
        os.makedirs(save_dir, exist_ok=True)

        # ğŸ”¥ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
        for filename in os.listdir(save_dir):
            file_path = os.path.join(save_dir, filename)
            try:
                if os.path.isfile(file_path):
                    os.remove(file_path)
                    print(f"ğŸ—‘ï¸ ê¸°ì¡´ íŒŒì¼ ì‚­ì œë¨: {file_path}")
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {file_path} / {e}")

        saved_paths = {}

        for field_name in files:
            file = files[field_name]
            save_path = os.path.join(save_dir, file.filename)

            # ì¸êµ¬ë°€ë„ ë°ì´í„° íŒŒì¼ ì´ë¦„ ë³€ê²½ ì²˜ë¦¬
            if field_name == "population":
                save_path = os.path.join(save_dir, "ì¸êµ¬ë°€ë„ ë°ì´í„°.txt")
            file.save(save_path)
            saved_paths[field_name] = save_path
            print(f"âœ… ì €ì¥ë¨: {field_name} â†’ {save_path}, ì‹¤ì œ íŒŒì¼ëª…: {file.filename}")  # ì‹¤ì œ íŒŒì¼ëª… ë¡œê·¸ ì¶”ê°€

        # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë¡œê·¸ ì¶”ê°€
        population_file_path = "data/ë°ì´í„°ì´ˆì•ˆ/ì¸êµ¬ë°€ë„ ë°ì´í„°.txt"
        print(f"ğŸ” ì¸êµ¬ë°€ë„ íŒŒì¼ ê²½ë¡œ í™•ì¸: {population_file_path}")
        print(f"   ì¡´ì¬ ì—¬ë¶€: {os.path.exists(population_file_path)}")
        print(f"   íŒŒì¼ ì—¬ë¶€: {os.path.isfile(population_file_path)}")

        # ğŸ”„ ì†Œë°©ì„œ ì£¼ì†Œ â†’ ì¢Œí‘œ ë³€í™˜ ì²˜ë¦¬
        if "fireStation" in saved_paths:
            print("ğŸ“Œ [ìë™ ì²˜ë¦¬] ì†Œë°©ì„œ ì£¼ì†Œ â†’ ì¢Œí‘œ ë³€í™˜ ì¤‘...")
            fire_file_path = saved_paths["fireStation"]
            df = pd.read_csv(fire_file_path, encoding="cp949")

            from time import sleep

            latitudes, longitudes, failed = [], [], []
            total = len(df)
            for idx, row in enumerate(df.iterrows()):
                _, row_data = row
                address = str(row_data["ì£¼ì†Œ"]).strip()
                lat, lng = kakao_geocode(address)
                latitudes.append(lat)
                longitudes.append(lng)
                if lat is None or lng is None:
                    failed.append(address)

                if (idx + 1) % 10 == 0 or idx == total - 1:
                    print(f"â³ ì£¼ì†Œ ë³€í™˜ ì§„í–‰ ì¤‘: {idx + 1}/{total} ({((idx + 1) / total * 100):.1f}%)")

                sleep(0.3)

            df["ìœ„ë„"] = latitudes
            df["ê²½ë„"] = longitudes
            os.makedirs("data/ì‚°ì¶œë°ì´í„°", exist_ok=True)
            df.to_csv("data/ì‚°ì¶œë°ì´í„°/ì†Œë°©ì„œ_ì¢Œí‘œ_ì¹´ì¹´ì˜¤.csv", index=False, encoding="utf-8-sig")
            print("âœ… ì†Œë°©ì„œ ì£¼ì†Œ ë³€í™˜ ì™„ë£Œ")

        # ğŸ”„ SHP â†’ ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ ì²˜ë¦¬
        if "boundaryshp" in saved_paths:
            print("ğŸ“Œ [ìë™ ì²˜ë¦¬] SHP â†’ ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ ì¤‘...")
            shp_path = saved_paths["boundaryshp"]
            gdf = gpd.read_file(shp_path)
            if gdf.crs != "EPSG:4326":
                gdf = gdf.to_crs(epsg=4326)

            gdf["ìœ„ë„"] = gdf.geometry.centroid.y
            gdf["ê²½ë„"] = gdf.geometry.centroid.x
            region_col = "TOT_REG_CD"
            df_geo = gdf[[region_col, "ìœ„ë„", "ê²½ë„"]].rename(columns={region_col: "ì§€ì—­ì½”ë“œ"})
            os.makedirs("data/ì‚°ì¶œë°ì´í„°", exist_ok=True)
            df_geo.to_csv("data/ì‚°ì¶œë°ì´í„°/ì§€ì—­ì½”ë“œ_ì¢Œí‘œ.csv", index=False, encoding="utf-8-sig")
            print("âœ… SHP ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ ì™„ë£Œ")

        # âœ… ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ìë™ ì‹¤í–‰
        print("ğŸš€ [í›„ì²˜ë¦¬] ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ìë™ ì‹¤í–‰ ì‹œì‘")
        with app.test_request_context():
            res = recommend()
            print("ğŸ¯ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ìë™ ì‹¤í–‰ ì™„ë£Œ")

        return jsonify({"message": "ëª¨ë“  íŒŒì¼ ì—…ë¡œë“œ ë° ìë™ ë³€í™˜ ì™„ë£Œ âœ…"}), 200

    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/server-status', methods=['GET'])
def check_server_status():
    return jsonify({"status": "success"}), 200

if __name__ == '__main__':
    app.run(host='localhost', port=5000)
